{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# mGTP model (SberDevices)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J2v62uISLylM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Preparation"
      ],
      "metadata": {
        "id": "ncQhosI5KTuW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.1 Installing and linking the required libraries**"
      ],
      "metadata": {
        "id": "A4fYL9_GNMW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.10.3"
      ],
      "metadata": {
        "id": "-R48OIroMHKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
      ],
      "metadata": {
        "id": "AYLCukxbOTUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2 Import data from local disk for model training**"
      ],
      "metadata": {
        "id": "5mWgT8g-R8YJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded_train = files.upload()\n",
        "uploaded_train_name = list(uploaded_train)[0]"
      ],
      "metadata": {
        "id": "7H2kpno1Sjsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dGj3l0AVIlnZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b754b43-94f9-4837-95ea-bdfa61eecf86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.3 Model loading**"
      ],
      "metadata": {
        "id": "MiTjLxB4PFpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://files.sberdisk.ru/s/NzeBqYE84TAQDiS/download -O model.zip\n",
        "# !unzip model.zip -d mgptxl\n",
        "# model_name = \"./mgptxl\"\n",
        "model_name = \"sberbank-ai/mGPT\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name, gradient_checkpointing=True, use_cache=False)"
      ],
      "metadata": {
        "id": "J-aSgzziXJCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.4 Data conversion**"
      ],
      "metadata": {
        "id": "NCJW9r7_dOFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, path, tokenizer, seq_length=512):\n",
        "        with open(path) as f:\n",
        "            data = f.read()\n",
        "        tokens = tokenizer.encode(data)\n",
        "        examples = []\n",
        "        for i in range(0, len(tokens) - seq_length + 1, seq_length):\n",
        "            examples.append(tokens[i:i + seq_length])\n",
        "        self.samples = torch.LongTensor(examples)\n",
        "        print('Loaded samples:', len(self.samples))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.samples[item]"
      ],
      "metadata": {
        "id": "5eZlIRxAPEsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_line(path):\n",
        "  df = pd.read_csv(path)\n",
        "  line = ''\n",
        "  for index, row in df.iterrows():\n",
        "    line += row['tj'].replace('\\n', ' ') + ' ' + row['pers'].replace('\\n', ' ') + '\\n'\n",
        "  file_name = path.split('.csv')[0]+'_converted.txt'\n",
        "  with open(file_name, 'w') as f:\n",
        "    f.write(line)\n",
        "  return file_name"
      ],
      "metadata": {
        "id": "_QlimUGmBe5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "up_train_con = convert_to_line(uploaded_train_name)"
      ],
      "metadata": {
        "id": "_0KSROqcDhp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(up_train_con, mode='r', encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "for i in range(5):\n",
        "    print(lines[i].replace('\\n', ''))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARmiKlEV1nGO",
        "outputId": "ca72c256-890f-4cb9-e36c-eb3f774ccff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ротибахӯр راتبه‌خور\n",
            "Дигар гашта аз ҷанг ҷустан сутӯҳ. دگر گشته از جنگ جستن ستوه\n",
            "нонтокт ммуриол نانتاکت مموریال\n",
            "Хуан круз реал خوان کروز رئال\n",
            "Ҳама гӯш доред овои ман, همه گوش دارید آوای من\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TextDataset(up_train_con, tokenizer)\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "id": "F6vmX8ucXbHA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e11f7d9-46b8-4897-cab7-ceeb01fe3dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded samples: 3587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Training"
      ],
      "metadata": {
        "id": "cpfw_fwHdyV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for n,p in model.named_parameters():\n",
        "  if 'transformer.h' in n:\n",
        "    layer_num = int(n.split('.')[2])\n",
        "    if 'ln_' not in n and layer_num > 0 and layer_num < 23:\n",
        "      p.requires_grad = False\n",
        "      print('Freeze', n)"
      ],
      "metadata": {
        "id": "Tj2fRbUsaEWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.cuda()\n",
        "optimizer = torch.optim.SGD(params=model.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "id": "G6557l32g4r4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(epoch): \n",
        "    path = '/content/drive/MyDrive/Model/saved_model_e' + str(epoch) + '.pth'\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "def load_model(epoch):\n",
        "  path = '/content/drive/MyDrive/Model/saved_model_e' + str(epoch) + '.pth'\n",
        "  model.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "id": "TOuCKgihSGzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.eval() \n",
        "model.train()\n",
        "last_epoch = -1\n",
        "max_epoch = 3\n",
        "#max_epoch = 9\n",
        "for epoch in range(0,max_epoch):\n",
        "  print('Epoch', epoch)\n",
        "  progressbar = tqdm(train_loader)\n",
        "  losses = []\n",
        "  for batch in progressbar:\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    batch = batch.to(model.device)\n",
        "    outputs = model(batch, labels=batch)\n",
        "    loss = outputs.loss\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    losses.append(loss.detach().item())\n",
        "    progressbar.set_description(\"Loss: %.3f\" % np.mean(losses[-10:]))\n",
        "    last_epoch += 1\n",
        "  save_model(epoch)"
      ],
      "metadata": {
        "id": "_tvoZB_GExpi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "442bec75-a1db-490e-deec-76e9fc674877"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss: 2.504: 100%|██████████| 3470/3470 [1:19:38<00:00,  1.38s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 2.409: 100%|██████████| 3470/3470 [1:19:36<00:00,  1.38s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_model(last_epoch)"
      ],
      "metadata": {
        "id": "HEfBlZOTfptZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Testing and metrics calculation"
      ],
      "metadata": {
        "id": "ZX3r93Qid885"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install levenshtein\n",
        "!pip install sacrebleu"
      ],
      "metadata": {
        "id": "Rnh-zqGekYK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sacrebleu.metrics import BLEU\n",
        "from Levenshtein import ratio"
      ],
      "metadata": {
        "id": "-c_anFoBbVpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cut(t, lenght): #функция для ограничения длины выводимого(генерируемого) текста\n",
        "  line = t.split('متن فارسی:')[1]\n",
        "  gen = line.split()\n",
        "  line = ''\n",
        "  lenght = min(lenght, len(gen))\n",
        "  for i in range(lenght):\n",
        "    line = line + ' ' + gen[i]\n",
        "  return line.strip()\n",
        "\n",
        "def transliteration(line):\n",
        "  text = 'Матни тоҷикӣ:' + line + 'متن فارسی:' \n",
        "  input_ids = tokenizer.encode(text, return_tensors=\"pt\").cuda()\n",
        "  out = model.generate(input_ids, min_length=100, max_length=100, eos_token_id=5, pad_token=1, top_k=10, top_p=0.0, no_repeat_ngram_size=5, do_sample=False) \n",
        "  generated_text = list(map(tokenizer.decode, out))[0]\n",
        "  return cut(generated_text, len(line.split()))"
      ],
      "metadata": {
        "id": "jsYqygtkl-gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bleu_score(pred, ref):\n",
        "  bleu = BLEU()\n",
        "  return bleu.corpus_score([pred], [[ref]]).score\n",
        "\n",
        "def get_levenshtein_ratio(pred, ref):\n",
        "  return(ratio(pred,ref))\n",
        "  \n",
        "def get_accuracy(ref, pred):\n",
        "  return sum([r == p for r, p in zip(ref[0], pred)]) / len(pred)\n",
        "\n",
        "def get_translit_file(file_input, file_output):     \n",
        "  col_names=['tj', 'pers', 'pers_prediction', 'bleu', 'levenshtein_ratio', 'accuracy']\n",
        "  df = pd.DataFrame(columns=col_names)\n",
        "\n",
        "  df['tj'] = pd.read_csv(file_input, delimiter = ',')['tj']\n",
        "  df['pers'] = pd.read_csv(file_input, delimiter = ',')['pers']\n",
        "    \n",
        "  for index, row in df.iterrows():\n",
        "    # print(row['tj'], row['pers'])\n",
        "    row['pers_prediction'] = transliteration(row['tj'])\n",
        "    row['bleu'] = get_bleu_score(row['pers_prediction'], row['pers'])\n",
        "    row['levenshtein_ratio'] = get_levenshtein_ratio(row['pers_prediction'], row['pers'])\n",
        "    row['accuracy'] = get_accuracy(row['pers'], row['pers_prediction'])\n",
        "      \n",
        "    #print(row)\n",
        "    print(f'''Rows completed: {index+1} / {df.shape[0]}''')\n",
        "\n",
        "  file_output_name = f'{file_output}.xlsx'\n",
        "  df.to_excel(file_output_name)\n",
        "  print(f'Result saved to file: {file_output_name}')"
      ],
      "metadata": {
        "id": "tmeKpovGWam9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "up_test = files.upload() \n",
        "test_name = list(up_test)[0]"
      ],
      "metadata": {
        "id": "7H_QCYkqlH1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df= pd.read_csv(test_name, delimiter = ';')\n",
        "# for index, row in df.iterrows():\n",
        "#   row['tj'] = str(row['tj']).strip()\n",
        "#   row['pers'] = str(row['pers']).strip()\n",
        "\n",
        "# df.to_csv(test_name+'_converted.csv', index=False)"
      ],
      "metadata": {
        "id": "8lO-LcjBs92M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_translit_file(test_name, 'mGPT_examples')"
      ],
      "metadata": {
        "id": "IB4g4UQqBsXp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}